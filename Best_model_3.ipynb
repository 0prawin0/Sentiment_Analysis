{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db3c77a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Praveen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "2024/01/16 22:39:25 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial warning can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "    - warn|w|warning|1: for a printed warning\n",
      "    - error|e|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re,string,unicodedata\n",
    "import nltk\n",
    "from wordcloud import WordCloud\n",
    "from nltk import ngrams\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.metrics import accuracy_score ,roc_auc_score,f1_score,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "df_train=pd.read_csv(\"train.csv\",encoding='latin-1')\n",
    "df_train=df_train[['text','sentiment']]\n",
    "df_train['text'] = df_train['text'].astype(str)\n",
    "df_train=df_train[df_train['sentiment']!='neutral']\n",
    "df_train['sentiment']=df_train['sentiment'].map({'positive':1,'negative':0})\n",
    "X=df_train['text']\n",
    "y=df_train['sentiment']\n",
    "\n",
    "class TextCleaner():\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return [self.clean_text(text) for text in X]\n",
    "    def clean_text(self, text):\n",
    "        text = str(text).lower()  # Make text lowercase\n",
    "        text = re.sub('\\[.*?\\]', '', text)  # Remove any sequence of characters in square brackets\n",
    "        text = re.sub('https?://\\S+|www\\.\\S+', '', text)  # Remove links\n",
    "        text = re.sub('<.*?>+', '', text)  # Remove HTML tags\n",
    "        text = re.sub('[%s]' % re.escape(string.punctuation), '', text)  # Remove punctuation\n",
    "        text = re.sub('\\n', '', text)  # Remove newline characters\n",
    "        text = re.sub('\\w*\\d\\w*', '', text)  # Remove words containing numbers\n",
    "        text = re.sub(r'[^a-z/A-Z/0-9/ ]', '', text)  # Remove special characters\n",
    "        return text\n",
    "\n",
    "class stopwords():\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return [self.stopw(text) for text in X]\n",
    "    \n",
    "    def stopw(self,text):\n",
    "        from nltk.corpus import stopwords\n",
    "        stopwords = stopwords.words('english')\n",
    "        stopwords=stopwords+['s','m','u','im','ye','id','atg','na','ta','gon','wan']\n",
    "        text= ' '.join([x for x in text.split() if x not in stopwords])\n",
    "        return text\n",
    "\n",
    "class lemma():\n",
    "    \n",
    "    def __init__(self,lemma_model):\n",
    "        self.lemma_model=lemma_model\n",
    "        \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        return [self.lemmatise(text) for text in X]\n",
    "    \n",
    "    def lemmatise(self,text):\n",
    "        return \" \".join([token.lemma_ for token in self.lemma_model(text)])\n",
    "\n",
    "def to_array(X):\n",
    "    return X.toarray()\n",
    "    \n",
    "pipeline = Pipeline([\n",
    "    ('cleaner', TextCleaner()),\n",
    "    ('stop_words_removal',stopwords()),\n",
    "    ('lemmatization',lemma(spacy.load(\"en_core_web_sm\", disable = ['parser','ner']))),\n",
    "    ('TF-IDF-fit',TfidfVectorizer()),\n",
    "    ('model',MultinomialNB())\n",
    "])\n",
   
    "# Set the tracking URI to the local tracking server\n",
    "mlflow.set_tracking_uri('http://127.0.0.1:5000')\n",
    "experiment_name = \"mlflow_pipeline_experiment\"\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "\n",
    "if experiment is None:\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "else:\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "pipeline = Pipeline([\n",
    "    ('cleaner', TextCleaner()),\n",
    "    ('stop_words_removal', stopwords()),\n",
    "    ('lemmatization', lemma(spacy.load(\"en_core_web_sm\", disable=['parser', 'ner']))),\n",
    "    ('TF-IDF', TfidfVectorizer()),\n",
    "    ('model', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Fit and transform TF-IDF on the training set\n",
    "X_train_tfidf = pipeline.named_steps['TF-IDF'].fit_transform(X_train)\n",
    "\n",
    "# Transform TF-IDF on the test set\n",
    "X_test_tfidf = pipeline.named_steps['TF-IDF'].transform(X_test)\n",
    "\n",
    "# Fit the rest of the pipeline on the training set\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = pipeline.predict(X_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1_train = f1_score(y_train, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "    \n",
    "with mlflow.start_run(run_name=\"Experiment\"):\n",
    "    mlflow.log_param(\"model_type\", 'multinomial')\n",
    "    mlflow.sklearn.log_model(pipeline, \"model\")\n",
    "    mlflow.log_metric(\"accuracy train\", accuracy_train)\n",
    "    mlflow.log_metric(\"accuracy test\", accuracy_test)\n",
    "    mlflow.log_metric(\"f1 train\", f1_train)\n",
    "    mlflow.log_metric(\"f1 test\", f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37be171",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
