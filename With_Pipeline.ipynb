{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db3c77a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Praveen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re,string,unicodedata\n",
    "import nltk\n",
    "from wordcloud import WordCloud\n",
    "from nltk import ngrams\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.svm import SVC\n",
    "# from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.metrics import accuracy_score ,roc_auc_score,f1_score,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import streamlit as st\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64210b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('train.csv',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2ac5fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>Age of User</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population -2020</th>\n",
       "      <th>Land Area (Km²)</th>\n",
       "      <th>Density (P/Km²)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>38928346</td>\n",
       "      <td>652860.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2877797</td>\n",
       "      <td>27400.0</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>43851044</td>\n",
       "      <td>2381740.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>77265</td>\n",
       "      <td>470.0</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Angola</td>\n",
       "      <td>32866272</td>\n",
       "      <td>1246700.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment Time of Tweet Age of User  \\\n",
       "0  I`d have responded, if I were going   neutral       morning        0-20   \n",
       "1                             Sooo SAD  negative          noon       21-30   \n",
       "2                          bullying me  negative         night       31-45   \n",
       "3                       leave me alone  negative       morning       46-60   \n",
       "4                        Sons of ****,  negative          noon       60-70   \n",
       "\n",
       "       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  \n",
       "0  Afghanistan          38928346         652860.0               60  \n",
       "1      Albania           2877797          27400.0              105  \n",
       "2      Algeria          43851044        2381740.0               18  \n",
       "3      Andorra             77265            470.0              164  \n",
       "4       Angola          32866272        1246700.0               26  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()\n",
    "#first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cee5abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train[['text','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97ea034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['text'] = df_train['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "492b1b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27481 entries, 0 to 27480\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text       27481 non-null  object\n",
      " 1   sentiment  27481 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 429.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aa4dacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train[df_train['sentiment']!='neutral']\n",
    "df_train['sentiment']=df_train['sentiment'].map({'positive':1,'negative':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf7b2b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_train['text']\n",
    "y=df_train['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8d7f50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCleaner():\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return [self.clean_text(text) for text in X]\n",
    "    def clean_text(self, text):\n",
    "        text = str(text).lower()  # Make text lowercase\n",
    "        text = re.sub('\\[.*?\\]', '', text)  # Remove any sequence of characters in square brackets\n",
    "        text = re.sub('https?://\\S+|www\\.\\S+', '', text)  # Remove links\n",
    "        text = re.sub('<.*?>+', '', text)  # Remove HTML tags\n",
    "        text = re.sub('[%s]' % re.escape(string.punctuation), '', text)  # Remove punctuation\n",
    "        text = re.sub('\\n', '', text)  # Remove newline characters\n",
    "        text = re.sub('\\w*\\d\\w*', '', text)  # Remove words containing numbers\n",
    "        text = re.sub(r'[^a-z/A-Z/0-9/ ]', '', text)  # Remove special characters\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69fb4511",
   "metadata": {},
   "outputs": [],
   "source": [
    "class stopwords():\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return [self.stopw(text) for text in X]\n",
    "    \n",
    "    def stopw(self,text):\n",
    "        from nltk.corpus import stopwords\n",
    "        stopwords = stopwords.words('english')\n",
    "        stopwords=stopwords+['s','m','u','im','ye','id','atg','na','ta','gon','wan']\n",
    "        text= ' '.join([x for x in text.split() if x not in stopwords])\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "657bce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lemma():\n",
    "    \n",
    "    def __init__(self,lemma_model):\n",
    "        self.lemma_model=lemma_model\n",
    "        \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        return [self.lemmatise(text) for text in X]\n",
    "    \n",
    "    def lemmatise(self,text):\n",
    "        return \" \".join([token.lemma_ for token in self.lemma_model(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8020134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_array(X):\n",
    "    return X.toarray()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63d6186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('cleaner', TextCleaner()),\n",
    "    ('stop_words_removal',stopwords()),\n",
    "    ('lemmatization',lemma(spacy.load(\"en_core_web_sm\", disable = ['parser','ner']))),\n",
    "    ('TF-IDF-fit',TfidfVectorizer()),\n",
    "    #('TF-IDF-Transform',FunctionTransformer(to_array,accept_sparse=True))\n",
    "    #('toarray',FunctionTransformer(to_array,accept_sparse=True)),\n",
    "    ('model',MultinomialNB())\n",
    "    \n",
    "        \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c291aec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;cleaner&#x27;,\n",
       "                 &lt;__main__.TextCleaner object at 0x0000022D72CE4C10&gt;),\n",
       "                (&#x27;stop_words_removal&#x27;,\n",
       "                 &lt;__main__.stopwords object at 0x0000022D72CE4C40&gt;),\n",
       "                (&#x27;lemmatization&#x27;,\n",
       "                 &lt;__main__.lemma object at 0x0000022D72CE4FD0&gt;),\n",
       "                (&#x27;TF-IDF-fit&#x27;, TfidfVectorizer()), (&#x27;model&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cleaner&#x27;,\n",
       "                 &lt;__main__.TextCleaner object at 0x0000022D72CE4C10&gt;),\n",
       "                (&#x27;stop_words_removal&#x27;,\n",
       "                 &lt;__main__.stopwords object at 0x0000022D72CE4C40&gt;),\n",
       "                (&#x27;lemmatization&#x27;,\n",
       "                 &lt;__main__.lemma object at 0x0000022D72CE4FD0&gt;),\n",
       "                (&#x27;TF-IDF-fit&#x27;, TfidfVectorizer()), (&#x27;model&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TextCleaner</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.TextCleaner object at 0x0000022D72CE4C10&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">stopwords</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.stopwords object at 0x0000022D72CE4C40&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">lemma</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.lemma object at 0x0000022D72CE4FD0&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('cleaner',\n",
       "                 <__main__.TextCleaner object at 0x0000022D72CE4C10>),\n",
       "                ('stop_words_removal',\n",
       "                 <__main__.stopwords object at 0x0000022D72CE4C40>),\n",
       "                ('lemmatization',\n",
       "                 <__main__.lemma object at 0x0000022D72CE4FD0>),\n",
       "                ('TF-IDF-fit', TfidfVectorizer()), ('model', MultinomialNB())])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b2e27ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=pipeline.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a3e713c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9306973048951903"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y,pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "777c19a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9348200942637085"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = f1_score(y,pred)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f6bc440-2c70-4f40-8953-48d91b85263e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the tracking URI to the local tracking server\n",
    "mlflow.set_tracking_uri('http://127.0.0.1:5000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47efde0d-9122-4300-8a50-a035e148f000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the experiment name\n",
    "experiment_name = \"mlflow_pipeline_experiment\"\n",
    "\n",
    "# Check if the experiment exists\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef58290e-7c30-4f3e-9de9-934ecab84326",
   "metadata": {},
   "outputs": [],
   "source": [
    "if experiment is None:\n",
    "    # If the experiment does not exist, create it\n",
    "    mlflow.create_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a741efb-4ded-4729-96e8-e40d96b13348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/01/15 14:42:45 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial warning can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "    - warn|w|warning|1: for a printed warning\n",
      "    - error|e|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the experiment\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Log model with MLflow\n",
    "with mlflow.start_run(run_name=\"Multinomial NB\"):\n",
    "    mlflow.sklearn.log_model(pipeline, \"model\")\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"f1 score\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebf08787-1467-4ac4-8078-1c2bb3e42a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_list = [XGBClassifier(),GradientBoostingClassifier(),MultinomialNB(),LGBMClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a74282c-10d3-4eb6-8f84-4988edce0272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in algo_list:\n",
    "#     pipeline = Pipeline([\n",
    "#         ('cleaner', TextCleaner()),\n",
    "#         ('stop_words_removal',stopwords()),\n",
    "#         ('lemmatization',lemma(spacy.load(\"en_core_web_sm\", disable = ['parser','ner']))),\n",
    "#         ('TF-IDF-fit',TfidfVectorizer()),\n",
    "#         #('TF-IDF-Transform',FunctionTransformer(to_array,accept_sparse=True))\n",
    "#         #('toarray',FunctionTransformer(to_array,accept_sparse=True)),\n",
    "#         ('model',x) \n",
    "#     ])\n",
    "\n",
    "#     pipeline.fit(X,y)\n",
    "#     accuracy = accuracy_score(y,pred)\n",
    "#     f1 = f1_score(y,pred)\n",
    "    \n",
    "#     with mlflow.start_run():\n",
    "#         mlflow.sklearn.log_model(pipeline, \"model\")\n",
    "#         mlflow.log_metric(\"accuracy\", accuracy)\n",
    "#         mlflow.log_metric(\"f1 score\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20aa1dd5-ba3a-4b38-836b-49708a841c96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 15640)\t0.2571424906013482\n",
      "  (0, 5412)\t0.3149185950804328\n",
      "  (0, 7661)\t0.15086296860729959\n",
      "  (0, 5635)\t0.4775029992055459\n",
      "  (0, 10402)\t0.15758568958029026\n",
      "  (0, 2313)\t0.4775029992055459\n",
      "  (0, 14689)\t0.2981295086824993\n",
      "  (0, 1713)\t0.19643866155469816\n",
      "  (0, 16294)\t0.13561132285904076\n",
      "  (0, 14343)\t0.15665890842767735\n",
      "  (0, 14327)\t0.271267984604292\n",
      "  (0, 10619)\t0.29513520459704845\n",
      "  (1, 15689)\t0.267992502645706\n",
      "  (1, 1427)\t0.19426305023805265\n",
      "  (1, 16033)\t0.29206491192518536\n",
      "  (1, 10277)\t0.1940793020173602\n",
      "  (1, 16300)\t0.21493779607552865\n",
      "  (1, 7559)\t0.24517549121339025\n",
      "  (1, 1928)\t0.262466231735059\n",
      "  (1, 7068)\t0.4725838794885963\n",
      "  (1, 7911)\t0.2332528735518853\n",
      "  (1, 8414)\t0.23633050767743236\n",
      "  (1, 856)\t0.5086067853282885\n",
      "  (2, 15686)\t0.4594803810367507\n",
      "  (2, 7803)\t0.5761583924333249\n",
      "  :\t:\n",
      "  (13088, 15970)\t0.30304172092993864\n",
      "  (13088, 9514)\t0.3629418484321256\n",
      "  (13088, 16049)\t0.3245944418348514\n",
      "  (13088, 15731)\t0.2717365951616619\n",
      "  (13088, 15223)\t0.18264209065177958\n",
      "  (13088, 5677)\t0.49623849172319695\n",
      "  (13088, 2229)\t0.24043655072741382\n",
      "  (13088, 10152)\t0.20877336904935107\n",
      "  (13088, 8566)\t0.22452185349594983\n",
      "  (13088, 15933)\t0.16472239891870802\n",
      "  (13088, 3720)\t0.28257655690163386\n",
      "  (13088, 1549)\t0.12444019274651427\n",
      "  (13088, 14351)\t0.10473948474494041\n",
      "  (13088, 14576)\t0.10220492371645616\n",
      "  (13088, 10402)\t0.1481052434473455\n",
      "  (13089, 13295)\t0.5383773776920567\n",
      "  (13089, 3767)\t0.43540567766410443\n",
      "  (13089, 3645)\t0.35036118068927574\n",
      "  (13089, 10791)\t0.406464210918333\n",
      "  (13089, 9767)\t0.2813154215933303\n",
      "  (13089, 6947)\t0.21596343439295615\n",
      "  (13089, 7007)\t0.18656084119699906\n",
      "  (13089, 1549)\t0.14928553068627598\n",
      "  (13089, 4314)\t0.18628600933446063\n",
      "  (13089, 14576)\t0.12261083769647971\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "for x in algo_list:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('cleaner', TextCleaner()),\n",
    "        ('stop_words_removal', stopwords()),\n",
    "        ('lemmatization', lemma(spacy.load(\"en_core_web_sm\", disable=['parser', 'ner']))),\n",
    "        ('TF-IDF', TfidfVectorizer()),\n",
    "        ('model', x)\n",
    "    ])\n",
    "\n",
    "    # Fit and transform TF-IDF on the training set\n",
    "    X_train_tfidf = pipeline.named_steps['TF-IDF'].fit_transform(X_train)\n",
    "    \n",
    "    # Transform TF-IDF on the test set\n",
    "    X_test_tfidf = pipeline.named_steps['TF-IDF'].transform(X_test)\n",
    "    \n",
    "    # Fit the rest of the pipeline on the training set\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_train = pipeline.predict(X_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    f1_train = f1_score(y_train, y_pred_train)\n",
    "    f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_param(\"model_type\", x)\n",
    "        mlflow.sklearn.log_model(pipeline, \"model\")\n",
    "        mlflow.log_metric(\"accuracy train\", accuracy_train)\n",
    "        mlflow.log_metric(\"accuracy test\", accuracy_test)\n",
    "        mlflow.log_metric(\"f1 train\", f1_train)\n",
    "        mlflow.log_metric(\"f1 test\", f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c381173-2d67-40f6-8e61-e2875f49c7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6912, number of negative: 6178\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21239\n",
      "[LightGBM] [Info] Number of data points in the train set: 13090, number of used features: 660\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.528037 -> initscore=0.112264\n",
      "[LightGBM] [Info] Start training from score 0.112264\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('cleaner', TextCleaner()),\n",
    "    ('stop_words_removal', stopwords()),\n",
    "    ('lemmatization', lemma(spacy.load(\"en_core_web_sm\", disable=['parser', 'ner']))),\n",
    "    ('TF-IDF', TfidfVectorizer()),\n",
    "    ('model', LGBMClassifier())\n",
    "])\n",
    "\n",
    "# Fit and transform TF-IDF on the training set\n",
    "X_train_tfidf = pipeline.named_steps['TF-IDF'].fit_transform(X_train)\n",
    "\n",
    "# Transform TF-IDF on the test set\n",
    "X_test_tfidf = pipeline.named_steps['TF-IDF'].transform(X_test)\n",
    "\n",
    "# Fit the rest of the pipeline on the training set\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = pipeline.predict(X_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7836a51-a605-4b8c-b2a8-1968b73dc1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Streamlit web app\n",
    "st.header(\"Streamlit demo\")\n",
    "\n",
    "st.sidebar.header(\"This is a web app\")\n",
    "\n",
    "# X_test = st.sidebar.slider(\"Select X to get yhat\", 0, 10, 5)\n",
    "\n",
    "X_test_values = X_test  # You can replace this with your actual values\n",
    "\n",
    "X_test = st.sidebar.selectbox(\"Select the sentence to know the sentiment\", X_test_values)\n",
    "\n",
    "st.write(\"X test is:\", X_test)\n",
    "\n",
    "if pipeline is not None:\n",
    "    yhat_test = pipeline.predict([[X_test]])\n",
    "\n",
    "    st.write(\"b0 is\", yhat_test)\n",
    "\n",
    "else:\n",
    "    st.write(\"Model not found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
